{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.24/06\n"
     ]
    }
   ],
   "source": [
    "import ROOT\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import uproot\n",
    "import os\n",
    "import logging\n",
    "import tensorflow as tf\n",
    "\n",
    "from script import utils\n",
    "from script import cms\n",
    "from script.models.layers import Clip, Divide, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best-cuts\n",
    "\n",
    "# bbA\n",
    "CUT_CAT1_BBA_W = [0.52525253, 0.51515152, 0.48484848, 0.48484848, 0.43434343,\n",
    "                  0.42424242, 0.39393939, 0.41414141, 0.4040404 , 0.47474747,\n",
    "                  0.45454545, 0.41414141, 0.50505051, 0.48484848, 0.51515152,\n",
    "                  0.53535354]  # computed on 100 bins\n",
    "\n",
    "CUT_CAT1_BBA_PU_W = [0.57142857, 0.6122449 , 0.57142857, 0.57142857, 0.46938776, \n",
    "                     0.46938776, 0.53061224, 0.48979592, 0.46938776, 0.53061224, \n",
    "                     0.53061224, 0.59183673, 0.59183673, 0.57142857, 0.57142857, \n",
    "                     0.6122449]   # computed on 50 bins\n",
    "\n",
    "# bbH\n",
    "CUT_CAT1_BBH_W = [0.52525253, 0.52525253, 0.46464646, 0.47474747, 0.46464646,\n",
    "                  0.41414141, 0.39393939, 0.41414141, 0.4040404 , 0.45454545,\n",
    "                  0.49494949, 0.47474747, 0.50505051, 0.51515152, 0.51515152,\n",
    "                  0.53535354]  # computed on 100 bins\n",
    "\n",
    "CUT_CAT1_BBH_PU_W = [0.6122449 , 0.59183673, 0.55102041, 0.57142857, 0.57142857,\n",
    "                     0.51020408, 0.51020408, 0.48979592, 0.46938776, 0.48979592,\n",
    "                     0.55102041, 0.63265306, 0.59183673, 0.55102041, 0.57142857, \n",
    "                     0.6122449]   # computed on 50 bins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hood = []\n",
    "data_hood = []\n",
    "\n",
    "masses = [130,150,170,200,250,300,350,400,450,500,600,700,800,1000,1200,1500]\n",
    "\n",
    "FEATURES_CAT1 = [\"dimuon_deltar\", \"dimuon_deltaphi\", \"dimuon_deltaeta\", \"met_pt\", \n",
    "                 \"deltar_bjet1_dimuon\", \"deltapt_bjet1_dimuon\", \"deltaeta_bjet1_dimuon\", \n",
    "                 \"bjet_1_pt\", \"bjet_1_eta\", \"deltaphi_bjet1_dimuon\",\n",
    "                 \"ljet_1_pt\", \"ljet_1_eta\", \"bjet_n\", \"ljet_n\"]\n",
    "\n",
    "FEATURES_CAT2 = [\"dimuon_deltar\", \"dimuon_deltaphi\", \"dimuon_deltaeta\", \"met_pt\",\n",
    "                 \"ljet_1_pt\", \"ljet_1_eta\", \"ljet_n\"]\n",
    "\n",
    "INTERVALS = [(115, 180),   # 130\n",
    "             (115, 200),   # 150\n",
    "             (120, 220),   # 170\n",
    "             (150, 250),   # 200\n",
    "             (200, 300),   # 250\n",
    "             (225, 375),   # 300\n",
    "             (275, 425),   # 350\n",
    "             (300, 500),   # 400\n",
    "             (350, 550),   # 450\n",
    "             (350, 650),   # 500\n",
    "             (400, 800),   # 600\n",
    "             (500, 900),   # 700\n",
    "             (600, 1000),  # 800\n",
    "             (700, 1800),  # 1000\n",
    "             (700, 1800),  # 1200\n",
    "             (700, 1800)]  # 1500\n",
    "\n",
    "tanbetas = [2,5,10,15,20,25,30,40,50,60]\n",
    "dibosons = ['WWTo2L2Nu','WZTo3LNu','ZZTo2L2Nu','ZZTo4L']\n",
    "singletops = ['s-channel','t-channel_antitop','t-channel_top','tW_antitop','tW_top']\n",
    "bkgttbar_treename = 'background_treeTTbar_UL2016'\n",
    "ttbar_binned = ['Incl_700to1000','Incl_1000toInf']\n",
    "bkgDY_treename = 'background_treeDY_UL2016'\n",
    "DY_binned = ['ZMM_50to120','ZMM_120to200','ZMM_200to400','ZMM_400to800','ZMM_800to1400','ZMM_1400to2300']\n",
    "datas = ['B','C','D','E','F','G','H']\n",
    "\n",
    "for mA in masses:\n",
    "    for tanb in tanbetas:\n",
    "        sgn_treename = 'signal_treeMSSM_bbA_mA' + str(mA) + '_tanb' + str(tanb) + '_UL2016'\n",
    "        sgn_treename2 = 'signal_treeMSSM_bbH_mA' + str(mA) + '_tanb' + str(tanb) + '_UL2016'\n",
    "        sgn_treename3 = 'signal_treeMSSM_ggA_mA' + str(mA) + '_tanb' + str(tanb) + '_UL2016'\n",
    "        sgn_treename4 = 'signal_treeMSSM_ggH_mA' + str(mA) + '_tanb' + str(tanb) + '_UL2016'\n",
    "        hood.append(sgn_treename)\n",
    "        hood.append(sgn_treename2)\n",
    "        hood.append(sgn_treename3)\n",
    "        hood.append(sgn_treename4)\n",
    "\n",
    "for diboson in dibosons:\n",
    "    bkgdiboson_treename = 'background_treediboson_' + diboson + '_UL2016'\n",
    "    hood.append(bkgdiboson_treename)\n",
    "\n",
    "for st in singletops:\n",
    "    bkgst_treename = 'background_treeST_' + st + '_UL2016'\n",
    "    hood.append(bkgst_treename)\n",
    "    \n",
    "hood.append(bkgttbar_treename)\n",
    "hood.append(bkgDY_treename)\n",
    "\n",
    "for ttbar in ttbar_binned:\n",
    "    bkgttbar_binned_treename = 'background_treeTTbar' + ttbar + '_UL2016'\n",
    "    hood.append(bkgttbar_binned_treename)\n",
    "    \n",
    "for dy in DY_binned:\n",
    "    bkgdy_binned_treename = 'background_tree' + dy + '_UL2016'\n",
    "    hood.append(bkgdy_binned_treename)\n",
    "\n",
    "for data in datas:\n",
    "    data_treename = 'background_treeULRun2016' + data\n",
    "    data_hood.append(data_treename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistics\n",
    "mean_cat1 = cms.retrieve_stat(cms.STATS_CAT1, which='mean', columns=FEATURES_CAT1)\n",
    "std_cat1 = cms.retrieve_stat(cms.STATS_CAT1, which='std', columns=FEATURES_CAT1)\n",
    "clip_cat1 = cms.retrieve_clip(cms.CLIP_CAT1, columns=FEATURES_CAT1)\n",
    "\n",
    "# cat 2.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-29 13:12:11.335233: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# preprocessing layers: clip, standardization, and mA normalization\n",
    "preproc_cat1 = dict(x=[Clip(min_value=clip_cat1[:, 0], max_value=clip_cat1[:, 1]),\n",
    "                       StandardScaler(mean=mean_cat1, std=std_cat1)],\n",
    "                    m=[Divide(value=1000.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_dummy_dataset(features):\n",
    "#     from collections import namedtuple\n",
    "    \n",
    "#     a = namedtuple('A', ['train_features'])\n",
    "#     a.train_features = namedtuple('A', ['shape'])\n",
    "#     a.train_features.shape = (len(features),)\n",
    "#     return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pNN_output_signal(df, mass, pth='./weigths/new/'):\n",
    "    \n",
    "    # model building and loading\n",
    "    df_1 = df[df[\"bjet_n\"] > 0]\n",
    "    df_2 = df[df[\"bjet_n\"] == 0]\n",
    "    \n",
    "    out = np.empty((df.shape[0]))\n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "    logger = tf.get_logger()\n",
    "    logger.setLevel(logging.ERROR)\n",
    "    # CAT 1\n",
    "    # data = get_dummy_dataset(features=FEATURES_CAT1)\n",
    "    model = utils.get_compiled_pnn(len(FEATURES_CAT1), dropout=0.25,\n",
    "                                   preprocess=preproc_cat1)\n",
    "    # utils.load_from_checkpoint(model, path='new/pnn-balanced-cat_1-case_2')\n",
    "    utils.load_from_checkpoint(model, path='tmp/pnn-cat_1-preproc-drop-l2')\n",
    "                   \n",
    "    sig = df_1[df_1['type'] == 1.0]\n",
    "    \n",
    "    # seleziona su `mass` e `interval`\n",
    "    x = sig[sig['mA'] == mass][FEATURES_CAT1]\n",
    "    m = mass * np.ones((x.shape[0], 1))\n",
    "    \n",
    "    # apply model\n",
    "    y_s = model.predict({'x': x, 'm': m}, batch_size=1024)\n",
    "        \n",
    "    # store\n",
    "    np.put(out, x.index.values, y_s)\n",
    "    \n",
    "    # CAT 2\n",
    "    # data = get_dummy_dataset(features=FEATURES_CAT2)\n",
    "    model = utils.get_compiled_pnn(len(FEATURES_CAT2))\n",
    "    utils.load_from_checkpoint(model, path= 'new/pnn-balanced-cat_2-case_2')\n",
    "\n",
    "    sig = df_2[df_2['type'] == 1.0]\n",
    "\n",
    "    # seleziona su `mass` e `interval`\n",
    "    x = sig[sig['mA'] == mass][FEATURES_CAT2]\n",
    "    m = mass * np.ones((x.shape[0], 1))\n",
    "\n",
    "    # apply model\n",
    "    y_s = model.predict({'x': x, 'm': m}, batch_size=1024)\n",
    "        \n",
    "    # store\n",
    "    np.put(out, x.index.values, y_s)\n",
    "        \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pNN_output_background(df, pth='./weigths/new/'):\n",
    "    \n",
    "    # model building and loading\n",
    "    df_1 = df[df[\"bjet_n\"] > 0]\n",
    "    df_2 = df[df[\"bjet_n\"] == 0]\n",
    "    \n",
    "    out = np.empty((df.shape[0], len(INTERVALS)))\n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "    logger = tf.get_logger()\n",
    "    logger.setLevel(logging.ERROR)\n",
    "    # CAT 1\n",
    "    # data = get_dummy_dataset(features=FEATURES_CAT1)\n",
    "    model = utils.get_compiled_pnn(len(FEATURES_CAT1), dropout=0.25,\n",
    "                                   preprocess=preproc_cat1)\n",
    "    # utils.load_from_checkpoint(model, path='new/pnn-balanced-cat_1-case_2')\n",
    "    utils.load_from_checkpoint(model, path='tmp/pnn-cat_1-preproc-drop-l2')\n",
    "                   \n",
    "    bkg = df_1[df_1['type'] == 0.0]\n",
    "    \n",
    "    for i, (mass, (low, up)) in enumerate(zip(masses, INTERVALS)):\n",
    "        # seleziona su `mass` e `interval`\n",
    "        b = bkg[(bkg['dimuon_mass'] > low) & (bkg['dimuon_mass'] < up)][FEATURES_CAT1]\n",
    "        \n",
    "        # features and mass\n",
    "        x = b.values\n",
    "        if x.size == 0:\n",
    "            continue\n",
    "        m = mass * np.ones((x.shape[0], 1))\n",
    "        \n",
    "        # apply model\n",
    "        y_b = model.predict({'x': x, 'm': m}, batch_size=1024)\n",
    "                   \n",
    "        # store\n",
    "        out[b.index.values, i] = np.squeeze(y_b)\n",
    "    \n",
    "    # CAT 2\n",
    "    # data = get_dummy_dataset(features=FEATURES_CAT2)\n",
    "    model = utils.get_compiled_pnn(len(FEATURES_CAT2))\n",
    "    utils.load_from_checkpoint(model, path='new/pnn-balanced-cat_2-case_2')\n",
    "\n",
    "    bkg = df_2[df_2['type'] == 0.0]\n",
    "\n",
    "    for i, (mass, (low, up)) in enumerate(zip(masses, INTERVALS)):\n",
    "        # seleziona su `mass` e `interval`\n",
    "        b = bkg[(bkg['dimuon_mass'] > low) & (bkg['dimuon_mass'] < up)][FEATURES_CAT2]\n",
    "\n",
    "        # features and mass\n",
    "        x = b.values\n",
    "        if x.size == 0:\n",
    "            continue\n",
    "        m = mass * np.ones((x.shape[0], 1))\n",
    "\n",
    "        # apply model\n",
    "        y_b = model.predict({'x': x, 'm': m}, batch_size=1024)\n",
    "                   \n",
    "        # store\n",
    "        out[b.index.values, i] = np.squeeze(y_b)\n",
    "        \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite_root_signal(input_file, tree, array_of_pNN):\n",
    "    print(\"Save new branch in original ROOT file\")\n",
    "    \n",
    "    myfile = ROOT.TFile(input_file, 'update')\n",
    "    mytree = myfile.Get(tree)\n",
    "    \n",
    "    pNN_output = np.array([0.5])\n",
    "    newBranch = mytree.Branch(\"pNN_output\", pNN_output, \"pNN_output/D\")\n",
    "    numOfEvents = mytree.GetEntries()\n",
    "    \n",
    "    for n in range(numOfEvents):\n",
    "        pNN_output[0] = array_of_pNN[n]\n",
    "        mytree.GetEntry(n)\n",
    "        newBranch.Fill()\n",
    "    \n",
    "    mytree.Write(\"\", ROOT.TFile.kOverwrite)\n",
    "    myfile.Close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite_root_background(input_file, tree, array_of_pNN):\n",
    "    print(\"Save new branch in original ROOT file\")\n",
    "    \n",
    "    myfile = ROOT.TFile(input_file, 'update')\n",
    "    mytree = myfile.Get(tree)\n",
    "    \n",
    "    listOfNewBranches = []\n",
    "    \n",
    "    pNN_output_130 = np.array([0.5])\n",
    "    pNN_output_150 = np.array([0.5])\n",
    "    pNN_output_170 = np.array([0.5])\n",
    "    pNN_output_200 = np.array([0.5])\n",
    "    pNN_output_250 = np.array([0.5])\n",
    "    pNN_output_300 = np.array([0.5])\n",
    "    pNN_output_350 = np.array([0.5])\n",
    "    pNN_output_400 = np.array([0.5])\n",
    "    pNN_output_450 = np.array([0.5])\n",
    "    pNN_output_500 = np.array([0.5])\n",
    "    pNN_output_600 = np.array([0.5])\n",
    "    pNN_output_700 = np.array([0.5])\n",
    "    pNN_output_800 = np.array([0.5])\n",
    "    pNN_output_1000 = np.array([0.5])\n",
    "    pNN_output_1200 = np.array([0.5])\n",
    "    pNN_output_1500 = np.array([0.5])\n",
    "\n",
    "    listOfNewBranches.append(mytree.Branch(\"pNN_output_130\", pNN_output_130, \"pNN_output_130/D\"))\n",
    "    listOfNewBranches.append(mytree.Branch(\"pNN_output_150\", pNN_output_150, \"pNN_output_150/D\"))\n",
    "    listOfNewBranches.append(mytree.Branch(\"pNN_output_170\", pNN_output_170, \"pNN_output_170/D\"))\n",
    "    listOfNewBranches.append(mytree.Branch(\"pNN_output_200\", pNN_output_200, \"pNN_output_200/D\"))\n",
    "    listOfNewBranches.append(mytree.Branch(\"pNN_output_250\", pNN_output_250, \"pNN_output_250/D\"))\n",
    "    listOfNewBranches.append(mytree.Branch(\"pNN_output_300\", pNN_output_300, \"pNN_output_300/D\"))\n",
    "    listOfNewBranches.append(mytree.Branch(\"pNN_output_350\", pNN_output_350, \"pNN_output_350/D\"))\n",
    "    listOfNewBranches.append(mytree.Branch(\"pNN_output_400\", pNN_output_400, \"pNN_output_400/D\"))\n",
    "    listOfNewBranches.append(mytree.Branch(\"pNN_output_450\", pNN_output_450, \"pNN_output_450/D\"))\n",
    "    listOfNewBranches.append(mytree.Branch(\"pNN_output_500\", pNN_output_500, \"pNN_output_500/D\"))\n",
    "    listOfNewBranches.append(mytree.Branch(\"pNN_output_600\", pNN_output_600, \"pNN_output_600/D\"))\n",
    "    listOfNewBranches.append(mytree.Branch(\"pNN_output_700\", pNN_output_700, \"pNN_output_700/D\"))\n",
    "    listOfNewBranches.append(mytree.Branch(\"pNN_output_800\", pNN_output_800, \"pNN_output_800/D\"))\n",
    "    listOfNewBranches.append(mytree.Branch(\"pNN_output_1000\", pNN_output_1000, \"pNN_output_1000/D\"))\n",
    "    listOfNewBranches.append(mytree.Branch(\"pNN_output_1200\", pNN_output_1200, \"pNN_output_1200/D\"))\n",
    "    listOfNewBranches.append(mytree.Branch(\"pNN_output_1500\", pNN_output_1500, \"pNN_output_1500/D\"))\n",
    "            \n",
    "    numOfEvents = mytree.GetEntries()\n",
    "    \n",
    "    for n in range(numOfEvents):\n",
    "        pNN_output_130[0] = array_of_pNN[n,0]\n",
    "        pNN_output_150[0] = array_of_pNN[n,1]\n",
    "        pNN_output_170[0] = array_of_pNN[n,2]\n",
    "        pNN_output_200[0] = array_of_pNN[n,3]\n",
    "        pNN_output_250[0] = array_of_pNN[n,4]\n",
    "        pNN_output_300[0] = array_of_pNN[n,5]\n",
    "        pNN_output_350[0] = array_of_pNN[n,6]\n",
    "        pNN_output_400[0] = array_of_pNN[n,7]\n",
    "        pNN_output_450[0] = array_of_pNN[n,8]\n",
    "        pNN_output_500[0] = array_of_pNN[n,9]\n",
    "        pNN_output_600[0] = array_of_pNN[n,10]\n",
    "        pNN_output_700[0] = array_of_pNN[n,11]\n",
    "        pNN_output_800[0] = array_of_pNN[n,12]\n",
    "        pNN_output_1000[0] = array_of_pNN[n,13]\n",
    "        pNN_output_1200[0] = array_of_pNN[n,14]\n",
    "        pNN_output_1500[0] = array_of_pNN[n,15]\n",
    "                \n",
    "        mytree.GetEntry(n)\n",
    "        \n",
    "        for newBranch in listOfNewBranches:\n",
    "            newBranch.Fill()\n",
    "            \n",
    "    mytree.Write(\"\", ROOT.TFile.kOverwrite)\n",
    "    myfile.Close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "fname = './root_file/'\n",
    "fileIn = fname\n",
    "valid_header=['mA', 'training', 'dimuon_deltar', 'dimuon_deltaphi', 'dimuon_deltaeta', \n",
    "              'dimuon_mass', 'dimuon_pt', 'met_pt', 'met_phi', 'met_eta', 'bjet_n', \n",
    "              'bjet_1_pt', 'bjet_1_eta', 'jetfwd_n', 'ljet_n', 'ljet_1_pt', 'ljet_1_eta', \n",
    "              'deltar_bjet1_dimuon', 'deltapt_bjet1_dimuon', 'deltaeta_bjet1_dimuon', \n",
    "              'deltaphi_bjet1_dimuon', 'PU_Weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_output_to_root_signal(tree, file, mass):\n",
    "    print (\"[signal] Reading trees {} in file {}\".format(tree, file))\n",
    "    data = uproot.open(fname + file)[tree]\n",
    "\n",
    "    out = data.arrays(valid_header, library=\"pd\")\n",
    "    out[\"type\"] = 1.0\n",
    "\n",
    "    mass = float(mass)\n",
    "\n",
    "    pNN_out_array = get_pNN_output_signal(out, mass)\n",
    "    \n",
    "    # update root file with output pNN\n",
    "    rewrite_root_signal(fileIn + file, tree, pNN_out_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_output_to_root_background(tree, file):\n",
    "    print (\"[background] Reading trees {} in file {}\".format(tree, file))\n",
    "    data = uproot.open(fname + file)[tree]\n",
    "\n",
    "    out = data.arrays(valid_header, library=\"pd\")\n",
    "    out[\"type\"] = 0.0\n",
    "\n",
    "    pNN_out_array = get_pNN_output_background(out)\n",
    "    \n",
    "    # update root file with output pNN\n",
    "    rewrite_root_background(fileIn + file, tree, pNN_out_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[background] Reading trees background_treeST_s-channel_UL2016 in file Out_ST_s-channel_UL2016.root\n",
      "Loaded from \"weights/tmp/pnn-cat_1-preproc-drop-l2/weights-18-0.943\"\n",
      "130\n",
      "<class 'numpy.ndarray'>\n",
      "150\n",
      "<class 'numpy.ndarray'>\n",
      "170\n",
      "<class 'numpy.ndarray'>\n",
      "200\n",
      "<class 'numpy.ndarray'>\n",
      "250\n",
      "<class 'numpy.ndarray'>\n",
      "300\n",
      "<class 'numpy.ndarray'>\n",
      "350\n",
      "<class 'numpy.ndarray'>\n",
      "400\n",
      "<class 'numpy.ndarray'>\n",
      "450\n",
      "<class 'numpy.ndarray'>\n",
      "500\n",
      "<class 'numpy.ndarray'>\n",
      "600\n",
      "<class 'numpy.ndarray'>\n",
      "700\n",
      "<class 'numpy.ndarray'>\n",
      "800\n",
      "<class 'numpy.ndarray'>\n",
      "1000\n",
      "<class 'numpy.ndarray'>\n",
      "1200\n",
      "<class 'numpy.ndarray'>\n",
      "1500\n",
      "<class 'numpy.ndarray'>\n",
      "Loaded from \"weights/new/pnn-balanced-cat_2-case_2/weights-73-0.976\"\n",
      "Save new branch in original ROOT file\n",
      "[background] Reading trees background_treeST_t-channel_antitop_UL2016 in file Out_ST_t-channel_antitop_UL2016.root\n",
      "Loaded from \"weights/tmp/pnn-cat_1-preproc-drop-l2/weights-18-0.943\"\n",
      "130\n",
      "<class 'numpy.ndarray'>\n",
      "150\n",
      "<class 'numpy.ndarray'>\n",
      "170\n",
      "<class 'numpy.ndarray'>\n",
      "200\n",
      "<class 'numpy.ndarray'>\n",
      "250\n",
      "<class 'numpy.ndarray'>\n",
      "300\n",
      "<class 'numpy.ndarray'>\n",
      "350\n",
      "<class 'numpy.ndarray'>\n",
      "400\n",
      "<class 'numpy.ndarray'>\n",
      "450\n",
      "<class 'numpy.ndarray'>\n",
      "500\n",
      "<class 'numpy.ndarray'>\n",
      "600\n",
      "<class 'numpy.ndarray'>\n",
      "700\n",
      "<class 'numpy.ndarray'>\n",
      "800\n",
      "<class 'numpy.ndarray'>\n",
      "1000\n",
      "<class 'numpy.ndarray'>\n",
      "1200\n",
      "<class 'numpy.ndarray'>\n",
      "1500\n",
      "<class 'numpy.ndarray'>\n",
      "Loaded from \"weights/new/pnn-balanced-cat_2-case_2/weights-73-0.976\"\n",
      "Save new branch in original ROOT file\n",
      "[background] Reading trees background_treeST_t-channel_top_UL2016 in file Out_ST_t-channel_top_UL2016.root\n",
      "Loaded from \"weights/tmp/pnn-cat_1-preproc-drop-l2/weights-18-0.943\"\n",
      "130\n",
      "<class 'numpy.ndarray'>\n",
      "150\n",
      "<class 'numpy.ndarray'>\n",
      "170\n",
      "<class 'numpy.ndarray'>\n",
      "200\n",
      "<class 'numpy.ndarray'>\n",
      "250\n",
      "<class 'numpy.ndarray'>\n",
      "300\n",
      "<class 'numpy.ndarray'>\n",
      "350\n",
      "<class 'numpy.ndarray'>\n",
      "400\n",
      "<class 'numpy.ndarray'>\n",
      "450\n",
      "<class 'numpy.ndarray'>\n",
      "500\n",
      "<class 'numpy.ndarray'>\n",
      "600\n",
      "<class 'numpy.ndarray'>\n",
      "700\n",
      "<class 'numpy.ndarray'>\n",
      "800\n",
      "<class 'numpy.ndarray'>\n",
      "1000\n",
      "<class 'numpy.ndarray'>\n",
      "1200\n",
      "<class 'numpy.ndarray'>\n",
      "1500\n",
      "<class 'numpy.ndarray'>\n",
      "Loaded from \"weights/new/pnn-balanced-cat_2-case_2/weights-73-0.976\"\n",
      "Save new branch in original ROOT file\n",
      "[background] Reading trees background_treeST_tW_antitop_UL2016 in file Out_ST_tW_antitop_UL2016.root\n",
      "Loaded from \"weights/tmp/pnn-cat_1-preproc-drop-l2/weights-18-0.943\"\n",
      "130\n",
      "<class 'numpy.ndarray'>\n",
      "150\n",
      "<class 'numpy.ndarray'>\n",
      "170\n",
      "<class 'numpy.ndarray'>\n",
      "200\n",
      "<class 'numpy.ndarray'>\n",
      "250\n",
      "<class 'numpy.ndarray'>\n",
      "300\n",
      "<class 'numpy.ndarray'>\n",
      "350\n",
      "<class 'numpy.ndarray'>\n",
      "400\n",
      "<class 'numpy.ndarray'>\n",
      "450\n",
      "<class 'numpy.ndarray'>\n",
      "500\n",
      "<class 'numpy.ndarray'>\n",
      "600\n",
      "<class 'numpy.ndarray'>\n",
      "700\n",
      "<class 'numpy.ndarray'>\n",
      "800\n",
      "<class 'numpy.ndarray'>\n",
      "1000\n",
      "<class 'numpy.ndarray'>\n",
      "1200\n",
      "<class 'numpy.ndarray'>\n",
      "1500\n",
      "<class 'numpy.ndarray'>\n",
      "Loaded from \"weights/new/pnn-balanced-cat_2-case_2/weights-73-0.976\"\n",
      "Save new branch in original ROOT file\n",
      "[background] Reading trees background_treeST_tW_top_UL2016 in file Out_ST_tW_top_UL2016.root\n",
      "Loaded from \"weights/tmp/pnn-cat_1-preproc-drop-l2/weights-18-0.943\"\n",
      "130\n",
      "<class 'numpy.ndarray'>\n",
      "150\n",
      "<class 'numpy.ndarray'>\n",
      "170\n",
      "<class 'numpy.ndarray'>\n",
      "200\n",
      "<class 'numpy.ndarray'>\n",
      "250\n",
      "<class 'numpy.ndarray'>\n",
      "300\n",
      "<class 'numpy.ndarray'>\n",
      "350\n",
      "<class 'numpy.ndarray'>\n",
      "400\n",
      "<class 'numpy.ndarray'>\n",
      "450\n",
      "<class 'numpy.ndarray'>\n",
      "500\n",
      "<class 'numpy.ndarray'>\n",
      "600\n",
      "<class 'numpy.ndarray'>\n",
      "700\n",
      "<class 'numpy.ndarray'>\n",
      "800\n",
      "<class 'numpy.ndarray'>\n",
      "1000\n",
      "<class 'numpy.ndarray'>\n",
      "1200\n",
      "<class 'numpy.ndarray'>\n",
      "1500\n",
      "<class 'numpy.ndarray'>\n",
      "Loaded from \"weights/new/pnn-balanced-cat_2-case_2/weights-73-0.976\"\n",
      "Save new branch in original ROOT file\n",
      "[background] Reading trees background_treeZMM_50to120_UL2016 in file Out_ZMM_50to120_UL2016.root\n",
      "Loaded from \"weights/tmp/pnn-cat_1-preproc-drop-l2/weights-18-0.943\"\n",
      "130\n",
      "<class 'numpy.ndarray'>\n",
      "150\n",
      "<class 'numpy.ndarray'>\n",
      "170\n",
      "<class 'numpy.ndarray'>\n",
      "200\n",
      "<class 'numpy.ndarray'>\n",
      "250\n",
      "<class 'numpy.ndarray'>\n",
      "300\n",
      "<class 'numpy.ndarray'>\n",
      "350\n",
      "<class 'numpy.ndarray'>\n",
      "400\n",
      "<class 'numpy.ndarray'>\n",
      "450\n",
      "<class 'numpy.ndarray'>\n",
      "500\n",
      "<class 'numpy.ndarray'>\n",
      "600\n",
      "<class 'numpy.ndarray'>\n",
      "700\n",
      "<class 'numpy.ndarray'>\n",
      "800\n",
      "<class 'numpy.ndarray'>\n",
      "1000\n",
      "<class 'numpy.ndarray'>\n",
      "1200\n",
      "<class 'numpy.ndarray'>\n",
      "1500\n",
      "<class 'numpy.ndarray'>\n",
      "Loaded from \"weights/new/pnn-balanced-cat_2-case_2/weights-73-0.976\"\n",
      "Save new branch in original ROOT file\n",
      "[background] Reading trees background_treeZMM_120to200_UL2016 in file Out_ZMM_120to200_UL2016.root\n",
      "Loaded from \"weights/tmp/pnn-cat_1-preproc-drop-l2/weights-18-0.943\"\n",
      "130\n",
      "<class 'numpy.ndarray'>\n",
      "150\n",
      "<class 'numpy.ndarray'>\n",
      "170\n",
      "<class 'numpy.ndarray'>\n",
      "200\n",
      "<class 'numpy.ndarray'>\n",
      "250\n",
      "<class 'numpy.ndarray'>\n",
      "300\n",
      "<class 'numpy.ndarray'>\n",
      "350\n",
      "<class 'numpy.ndarray'>\n",
      "400\n",
      "<class 'numpy.ndarray'>\n",
      "450\n",
      "<class 'numpy.ndarray'>\n",
      "500\n",
      "<class 'numpy.ndarray'>\n",
      "600\n",
      "<class 'numpy.ndarray'>\n",
      "700\n",
      "<class 'numpy.ndarray'>\n",
      "800\n",
      "<class 'numpy.ndarray'>\n",
      "1000\n",
      "<class 'numpy.ndarray'>\n",
      "1200\n",
      "<class 'numpy.ndarray'>\n",
      "1500\n",
      "<class 'numpy.ndarray'>\n",
      "Loaded from \"weights/new/pnn-balanced-cat_2-case_2/weights-73-0.976\"\n",
      "Save new branch in original ROOT file\n",
      "[background] Reading trees background_treeZMM_200to400_UL2016 in file Out_ZMM_200to400_UL2016.root\n",
      "Loaded from \"weights/tmp/pnn-cat_1-preproc-drop-l2/weights-18-0.943\"\n",
      "130\n",
      "<class 'numpy.ndarray'>\n",
      "150\n",
      "<class 'numpy.ndarray'>\n",
      "170\n",
      "<class 'numpy.ndarray'>\n",
      "200\n",
      "<class 'numpy.ndarray'>\n",
      "250\n",
      "<class 'numpy.ndarray'>\n",
      "300\n",
      "<class 'numpy.ndarray'>\n",
      "350\n",
      "<class 'numpy.ndarray'>\n",
      "400\n",
      "<class 'numpy.ndarray'>\n",
      "450\n",
      "<class 'numpy.ndarray'>\n",
      "500\n",
      "<class 'numpy.ndarray'>\n",
      "600\n",
      "<class 'numpy.ndarray'>\n",
      "700\n",
      "<class 'numpy.ndarray'>\n",
      "800\n",
      "<class 'numpy.ndarray'>\n",
      "1000\n",
      "<class 'numpy.ndarray'>\n",
      "1200\n",
      "<class 'numpy.ndarray'>\n",
      "1500\n",
      "<class 'numpy.ndarray'>\n",
      "Loaded from \"weights/new/pnn-balanced-cat_2-case_2/weights-73-0.976\"\n",
      "Save new branch in original ROOT file\n",
      "[background] Reading trees background_treeZMM_400to800_UL2016 in file Out_ZMM_400to800_UL2016.root\n",
      "Loaded from \"weights/tmp/pnn-cat_1-preproc-drop-l2/weights-18-0.943\"\n",
      "130\n",
      "<class 'numpy.ndarray'>\n",
      "150\n",
      "<class 'numpy.ndarray'>\n",
      "170\n",
      "<class 'numpy.ndarray'>\n",
      "200\n",
      "<class 'numpy.ndarray'>\n",
      "250\n",
      "<class 'numpy.ndarray'>\n",
      "300\n",
      "<class 'numpy.ndarray'>\n",
      "350\n",
      "<class 'numpy.ndarray'>\n",
      "400\n",
      "<class 'numpy.ndarray'>\n",
      "450\n",
      "<class 'numpy.ndarray'>\n",
      "500\n",
      "<class 'numpy.ndarray'>\n",
      "600\n",
      "<class 'numpy.ndarray'>\n",
      "700\n",
      "<class 'numpy.ndarray'>\n",
      "800\n",
      "<class 'numpy.ndarray'>\n",
      "1000\n",
      "<class 'numpy.ndarray'>\n",
      "1200\n",
      "<class 'numpy.ndarray'>\n",
      "1500\n",
      "<class 'numpy.ndarray'>\n",
      "Loaded from \"weights/new/pnn-balanced-cat_2-case_2/weights-73-0.976\"\n",
      "Save new branch in original ROOT file\n",
      "[background] Reading trees background_treeZMM_800to1400_UL2016 in file Out_ZMM_800to1400_UL2016.root\n",
      "Loaded from \"weights/tmp/pnn-cat_1-preproc-drop-l2/weights-18-0.943\"\n",
      "130\n",
      "<class 'numpy.ndarray'>\n",
      "150\n",
      "<class 'numpy.ndarray'>\n",
      "170\n",
      "<class 'numpy.ndarray'>\n",
      "200\n",
      "<class 'numpy.ndarray'>\n",
      "250\n",
      "<class 'numpy.ndarray'>\n",
      "300\n",
      "<class 'numpy.ndarray'>\n",
      "350\n",
      "<class 'numpy.ndarray'>\n",
      "400\n",
      "<class 'numpy.ndarray'>\n",
      "450\n",
      "<class 'numpy.ndarray'>\n",
      "500\n",
      "<class 'numpy.ndarray'>\n",
      "600\n",
      "<class 'numpy.ndarray'>\n",
      "700\n",
      "<class 'numpy.ndarray'>\n",
      "800\n",
      "<class 'numpy.ndarray'>\n",
      "1000\n",
      "<class 'numpy.ndarray'>\n",
      "1200\n",
      "<class 'numpy.ndarray'>\n",
      "1500\n",
      "<class 'numpy.ndarray'>\n",
      "Loaded from \"weights/new/pnn-balanced-cat_2-case_2/weights-73-0.976\"\n",
      "Save new branch in original ROOT file\n",
      "[background] Reading trees background_treeZMM_1400to2300_UL2016 in file Out_ZMM_1400to2300_UL2016.root\n",
      "Loaded from \"weights/tmp/pnn-cat_1-preproc-drop-l2/weights-18-0.943\"\n",
      "130\n",
      "<class 'numpy.ndarray'>\n",
      "150\n",
      "<class 'numpy.ndarray'>\n",
      "170\n",
      "<class 'numpy.ndarray'>\n",
      "200\n",
      "<class 'numpy.ndarray'>\n",
      "250\n",
      "<class 'numpy.ndarray'>\n",
      "300\n",
      "<class 'numpy.ndarray'>\n",
      "350\n",
      "<class 'numpy.ndarray'>\n",
      "400\n",
      "<class 'numpy.ndarray'>\n",
      "450\n",
      "<class 'numpy.ndarray'>\n",
      "500\n",
      "<class 'numpy.ndarray'>\n",
      "600\n",
      "<class 'numpy.ndarray'>\n",
      "700\n",
      "<class 'numpy.ndarray'>\n",
      "800\n",
      "<class 'numpy.ndarray'>\n",
      "1000\n",
      "<class 'numpy.ndarray'>\n",
      "1200\n",
      "<class 'numpy.ndarray'>\n",
      "1500\n",
      "<class 'numpy.ndarray'>\n",
      "Loaded from \"weights/new/pnn-balanced-cat_2-case_2/weights-73-0.976\"\n",
      "Save new branch in original ROOT file\n"
     ]
    }
   ],
   "source": [
    "for tree in hood:\n",
    "    for file in os.listdir(fileIn):\n",
    "        t_splits = tree.split('_')\n",
    "        f_splits = file.split('_')\n",
    "        \n",
    "        kind = t_splits[0]\n",
    "        \n",
    "        if kind == 'signal':\n",
    "            if f_splits[2] == 'bbH' or f_splits[2] == 'bbA':\n",
    "                # if file.split('_')[1] + '_' + file.split('_')[2] + '_' + file.split('_')[3] + '_' + file.split('_')[4] != tree.split('_')[1][4:8] + '_' + tree.split('_')[2] + '_' + tree.split('_')[3] + '_' + tree.split('_')[4]:\n",
    "                if '_'.join(f_splits[1:5]) != t_splits[1][4:8] + '_' + '_'.join(t_splits[2:5]):\n",
    "                    continue\n",
    "                \n",
    "                write_output_to_root_signal(tree, file, mass=f_splits[3][2:])\n",
    "                \n",
    "        if kind == 'background':\n",
    "            bkg = f_splits[1]\n",
    "            \n",
    "            if bkg == 'diboson':\n",
    "                # if file.split('_')[1] + file.split('_')[2] != tree.split('_')[1][4:11] + tree.split('_')[2]:\n",
    "                if ''.join(f_splits[1:3]) != t_splits[1][4:11] + t_splits[2]:\n",
    "                    continue\n",
    "                \n",
    "                write_output_to_root_background(tree, file)\n",
    "            \n",
    "            elif bkg == 'ST':\n",
    "                if f_splits[2:-1] != t_splits[2:-1]:\n",
    "                    continue\n",
    "                    \n",
    "                write_output_to_root_background(tree, file)\n",
    "                \n",
    "            elif bkg == 'DY':\n",
    "                if f_splits[1] != t_splits[1][4:6]:\n",
    "                    continue\n",
    "                    \n",
    "                write_output_to_root_background(tree, file)\n",
    "\n",
    "            elif bkg == 'TTbarIncl':\n",
    "                if f_splits[1] != t_splits[1][4:13]:\n",
    "                    continue\n",
    "                \n",
    "                if f_splits[2] != t_splits[2]:\n",
    "                    continue\n",
    "                    \n",
    "                write_output_to_root_background(tree, file)\n",
    "\n",
    "            elif bkg == 'TTbar':\n",
    "                if f_splits[1] != t_splits[1][4:9] or t_splits[1][4:13] == \"TTbarIncl\":\n",
    "                    continue\n",
    "                    \n",
    "                write_output_to_root_background(tree, file)\n",
    "\n",
    "            elif bkg == 'ZMM':\n",
    "                if f_splits[1] != t_splits[1][4:7]:\n",
    "                    continue\n",
    "                \n",
    "                if f_splits[2] != t_splits[2]:\n",
    "                    continue\n",
    "                    \n",
    "                write_output_to_root_background(tree, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop for data\n",
    "\n",
    "for tree in data_hood: \n",
    "    for file in os.listdir(fileIn): \n",
    "        if tree.split('_')[0] == 'background': \n",
    "            if file.split('_')[1][2:9] == 'Run2016':     \n",
    "                if file.split('_')[1][2:10] != tree.split('_')[1][6:14]:\n",
    "                    continue\n",
    "                    \n",
    "                print (\"Reading trees {} in file {}\".format(tree, file))\n",
    "                data = uproot.open(fname + file)[tree]\n",
    "                \n",
    "                out = data.arrays(valid_header, library=\"pd\")\n",
    "                out.to_csv(\"./output_csv/\" + file.split(\".\")[0] + \".csv\") \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
